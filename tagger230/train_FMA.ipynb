{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import os\n",
    "import time\n",
    "import h5py\n",
    "import sys\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from math import floor\n",
    "from music_tagger_ftuning\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import save_data, load_dataset, save_dataset, sort_result, predict_label, load_gt, plot_confusion_matrix, extract_melgrams\n",
    "\n",
    "TRAIN = 1\n",
    "TEST = 0\n",
    "\n",
    "SAVE_MODEL = 1\n",
    "SAVE_WEIGHTS = 1\n",
    "\n",
    "LOAD_MODEL = 1\n",
    "LOAD_WEIGHTS = 0\n",
    "\n",
    "# Dataset\n",
    "MULTIFRAMES = 0\n",
    "SAVE_DB = 1\n",
    "LOAD_DB = 0\n",
    "\n",
    "# Model parameters\n",
    "nb_classes = 7\n",
    "nb_epoch = 1\n",
    "batch_size = 100\n",
    "\n",
    "time_elapsed = 0\n",
    "\n",
    "\n",
    "# GTZAN Dataset Tags\n",
    "tags = ['blues', 'classical', 'country', 'hiphop', 'jazz',  'pop',  'rock']\n",
    "tags = np.array(tags)\n",
    "\n",
    "# Paths to set\n",
    "model_name = \"6Conv1GRU\"\n",
    "model_path = \"6Conv1GRU_trained/\" + model_name + \"/\"\n",
    "weights_path = \"6Conv1GRU_trained/\" + model_name + \"/weights/\"\n",
    "\n",
    "# Create directories for the models & weights\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "    print 'Path created: ', model_path\n",
    "\n",
    "if not os.path.exists(weights_path):\n",
    "    os.makedirs(weights_path)\n",
    "    print 'Path created: ', weights_path\n",
    "\n",
    "# Divide the song into multiple frames of 29.1s or center crop\n",
    "train_songs_list = \"music/train_FMA/train_FMA_list_shuffled.txt\"\n",
    "train_songs_tags = \"music/train_FMA/train_FMA_labels_shuffled.txt\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Data Loading\n",
    "if LOAD_DB:\n",
    "    X_train, X_test, y_train, y_test = load_dataset('')\n",
    "\n",
    "# Compute mel-spectogram for all the frames\n",
    "else:\n",
    "    #We dont care about MULTFRAMES and num_song_genres here, train set is 30s long each song\n",
    "    X_train, num_frames_train = extract_melgrams(train_songs_list, MULTIFRAMES, process_all_song=False, num_songs_genre='')\n",
    "    print('X_train shape:', X_train.shape)\n",
    "#     X_test, y_test, num_frames_test = extract_melgrams(test_songs_list, MULTIFRAMES, process_all_song=False, num_songs_genre=10)\n",
    "\n",
    "y_train  = open(train_songs_tags, 'r').read().splitlines()\n",
    "\n",
    "\n",
    "print(X_train.shape, 'train samples')\n",
    "# print(X_test.shape, 'test samples')\n",
    "\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "# y_test = np.array(y_test)\n",
    "\n",
    "if SAVE_DB:\n",
    "    if MULTIFRAMES:\n",
    "        save_dataset('music_dataset/music_dataset_multiframe_train.h5', X_train, y_train,num_frames_train)\n",
    "        save_dataset('music_dataset/music_dataset_multiframe_test.h5', X_test,y_test,num_frames_test)\n",
    "    else:\n",
    "        save_dataset('music_dataset/music_dataset_FMA.h5', X_train, X_test, y_train, y_test)\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "# Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "print 'Shape labels y_train: ', Y_train.shape\n",
    "# print 'Shape labels y_test: ', Y_test.shape\n",
    "\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "model = music_tagger_6cnv1gru(LOAD_WEIGHTS)\n",
    "#model = MusicTaggerCNN(weights='msd', input_tensor=(1, 96, 1366))\n",
    "#sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Save model architecture\n",
    "if SAVE_MODEL:\n",
    "    json_string = model.to_json()\n",
    "    f = open(model_path+model_name+\".json\", 'w')\n",
    "    f.write(json_string)\n",
    "    f.close()\n",
    "\n",
    "# Train model\n",
    "if TRAIN:\n",
    "    try:\n",
    "        print (\"Training the model\")\n",
    "        f_train = open(model_path+model_name+\"_scores_training.txt\", 'w')\n",
    "        f_test = open(model_path+model_name+\"_scores_test.txt\", 'w')\n",
    "        f_scores = open(model_path+model_name+\"_scores.txt\", 'w')\n",
    "        for epoch in range(1,nb_epoch+1):\n",
    "            t0 = time.time()\n",
    "            print (\"Number of epoch: \" +str(epoch)+\"/\"+str(nb_epoch))\n",
    "            sys.stdout.flush()\n",
    "            scores = model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=1, verbose=1, validation_data=(X_test, Y_test))\n",
    "            time_elapsed = time_elapsed + time.time() - t0\n",
    "            print (\"Time Elapsed: \" +str(time_elapsed))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            score_train = model.evaluate(X_train, Y_train, verbose=0)\n",
    "            print('Train Loss:', score_train[0])\n",
    "            print('Train Accuracy:', score_train[1])\n",
    "            f_train.write(str(score_train)+\"\\n\")\n",
    "\n",
    "            score_test = model.evaluate(X_test, Y_test, verbose=0)\n",
    "            print('Test Loss:', score_test[0])\n",
    "            print('Test Accuracy:', score_test[1])\n",
    "            f_test.write(str(score_test)+\"\\n\")\n",
    "\n",
    "            f_scores.write(str(score_train[0])+\",\"+str(score_train[1])+\",\"+str(score_test[0])+\",\"+str(score_test[1]) + \"\\n\")\n",
    "\n",
    "            if SAVE_WEIGHTS and epoch % 5 == 0:\n",
    "                model.save_weights(weights_path + model_name + \"_epoch_\" + str(epoch) + \".h5\")\n",
    "                print(\"Saved model to disk in: \" + weights_path + model_name + \"_epoch\" + str(epoch) + \".h5\")\n",
    "\n",
    "        f_train.close()\n",
    "        f_test.close()\n",
    "        f_scores.close()\n",
    "\n",
    "        # Save time elapsed\n",
    "        f = open(model_path+model_name+\"_time_elapsed.txt\", 'w')\n",
    "        f.write(str(time_elapsed))\n",
    "        f.close()\n",
    "\n",
    "    # Save files when an sudden close happens / ctrl C\n",
    "    except:\n",
    "        f_train.close()\n",
    "        f_test.close()\n",
    "        f_scores.close()\n",
    "        # Save time elapsed\n",
    "        f = open(model_path + model_name + \"_time_elapsed.txt\", 'w')\n",
    "        f.write(str(time_elapsed))\n",
    "        f.close()\n",
    "    finally:\n",
    "        f_train.close()\n",
    "        f_test.close()\n",
    "        f_scores.close()\n",
    "        # Save time elapsed\n",
    "        f = open(model_path + model_name + \"_time_elapsed.txt\", 'w')\n",
    "        f.write(str(time_elapsed))\n",
    "        f.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (genre_detect)",
   "language": "python",
   "name": "genre_detect"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
